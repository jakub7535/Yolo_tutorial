{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0310cb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import urllib\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83698a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Detection:\n",
    "    def __init__(self, model_name = 'yolov3', input_square_size=416,\n",
    "                 path_yolo_classes='net/coco.txt', output_height=800):\n",
    "        self.model_name = model_name\n",
    "        path_weights = 'net/{}.weights'.format(self.model_name)\n",
    "        path_cfg = 'net/{}.cfg'.format(self.model_name)\n",
    "        self.net = cv2.dnn.readNet(path_weights, path_cfg)\n",
    "        self.grid_per_width = int(round(input_square_size/32))\n",
    "        self.input_square_size = self.grid_per_width * 32\n",
    "        if input_square_size%32:\n",
    "            print('''Value of input_square_size={} is indivisible by 32, \n",
    "input_square_size={} will be used instead. \n",
    "Choose input size that is integer multiple of 32(eg.320,416,620,...).'''.format(input_square_size, \n",
    "                                                                                self.input_square_size))\n",
    "        \n",
    "        self.is_scale_output = True\n",
    "        self.output_height = output_height\n",
    "        \n",
    "        if cv2.cuda.getCudaEnabledDeviceCount():    \n",
    "            self.net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "            self.net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
    "            print('GPU is enabled.')\n",
    "        else:\n",
    "            print('GPU is NOT enabled. OpenCV-{} will use CPU instead.'.format(cv2.__version__))\n",
    "        \n",
    "        print('Detection grid sizes: ({0}x{0}), ({1}x{1}), ({2}x{2}).'.format(self.grid_per_width, \n",
    "                                                2*self.grid_per_width, 4*self.grid_per_width))\n",
    "            \n",
    "        with open(path_yolo_classes, 'r') as f:\n",
    "            self.classes = f.read().splitlines()    \n",
    "        \n",
    "        self.anchor_box_show = False\n",
    "        self.grid_show = False   \n",
    "        self.is_pause = False\n",
    "        \n",
    "        self.MIN_confidence = 0.5\n",
    "        self.IOU_threshold = 0.4\n",
    "        self.FPS = None\n",
    "        self.start_time = None\n",
    "\n",
    "        self.font = cv2.FONT_HERSHEY_PLAIN\n",
    "        self.colors = ((255,0,0), (0,255,0), (0,0,255), (255,255,0), (0,255,255), (255,0,255), (128,0,0))        \n",
    "        self.anchors = [[116, 90, 156, 198, 373, 326], [30, 61, 62, 45, 59, 119], [10, 13, 16, 30, 33, 23]]\n",
    "        self.img = None\n",
    "        self.height, self.width = None, None\n",
    "        self.boxes = None\n",
    "        self.confidences = None\n",
    "        self.class_ids = None\n",
    "        self.grid_cells = None\n",
    "        self.anchor_boxes = None\n",
    "        self.anchor_centers = None\n",
    "        self.detection_outputs = None\n",
    "        \n",
    "    def detect(self, img):\n",
    "        self.start_time = time.time()\n",
    "        blob = cv2.dnn.blobFromImage(img, 1 / 255, (self.input_square_size, self.input_square_size),\n",
    "                                     (0, 0, 0), swapRB=True, crop=False)\n",
    "        \n",
    "        self.net.setInput(blob)\n",
    "        output_layers_names = self.net.getUnconnectedOutLayersNames()\n",
    "        self.layerOutputs = self.net.forward(output_layers_names)\n",
    "        if self.is_scale_output:\n",
    "            img = image_resize(img, height = self.output_height)\n",
    "        self.img = img\n",
    "        self.height, self.width, _ = self.img.shape\n",
    "        \n",
    "        boxes = []\n",
    "        confidences = []\n",
    "        class_ids = []\n",
    "        grid_cells = []\n",
    "        anchor_boxes = []\n",
    "        anchor_centers = []\n",
    "        detection_outputs = []\n",
    "\n",
    "        for i, output in enumerate(self.layerOutputs):\n",
    "            if self.model_name == 'yolov4':\n",
    "                if i==0:\n",
    "                    i=2\n",
    "                elif i==2:\n",
    "                    i=0\n",
    "            for j, detection in enumerate(output):\n",
    "                scores = detection[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = detection[4] * scores[class_id]\n",
    "\n",
    "                if confidence > 0.01:\n",
    "                    anchor_box = self.anchors[i][2 * (j % 3):2 * (j % 3) + 2]\n",
    "                    grid_cell = [int(j / 3) % (self.grid_per_width * 2 ** i),\n",
    "                                 int(j / (self.grid_per_width * 3 * 2 ** i))]\n",
    "                    center_x = int(round(detection[0] * self.width))\n",
    "                    center_y = int(round(detection[1] * self.height))\n",
    "                    w = int(round(detection[2] * self.width))\n",
    "                    h = int(round(detection[3] * self.height))\n",
    "                    x = int(round(center_x - w / 2))\n",
    "                    y = int(round(center_y - h / 2))\n",
    "\n",
    "                    boxes.append([x, y, w, h])\n",
    "                    confidences.append((float(confidence)))\n",
    "                    class_ids.append(class_id)\n",
    "                    grid_cells.append(grid_cell)\n",
    "                    anchor_boxes.append(anchor_box)\n",
    "                    anchor_centers.append((center_x, center_y))\n",
    "                    detection_outputs.append(i)\n",
    "            \n",
    "        self.boxes = boxes\n",
    "        self.confidences = confidences\n",
    "        self.class_ids = class_ids\n",
    "        self.grid_cells = grid_cells\n",
    "        self.anchor_boxes = anchor_boxes\n",
    "        self.anchor_centers = anchor_centers\n",
    "        self.detection_outputs = detection_outputs\n",
    "    \n",
    "    def draw_img(self):\n",
    "        img = self.img.copy()\n",
    "        cv2.putText(img, \"IOU:  {0:.2f}\".format(self.IOU_threshold), (20, 40), self.font, 3, (0, 0, 255), 3)\n",
    "        cv2.putText(img, \"CONF: {0:.2f}\".format(self.MIN_confidence), (20, 80), self.font, 3, (255, 0, 0), 3)\n",
    "\n",
    "        indexes = cv2.dnn.NMSBoxes(self.boxes, self.confidences, self.MIN_confidence, self.IOU_threshold)\n",
    "        if len(indexes) > 0:\n",
    "            for c, i in enumerate(indexes.flatten()):\n",
    "                x, y, w, h = self.boxes[i]\n",
    "                label = str(self.classes[self.class_ids[i]])\n",
    "                confidence = self.confidences[i]\n",
    "                color = self.colors[c%len(self.colors)]\n",
    "                cv2.rectangle(img, (x, y), (x + w, y + h), color, int(8 / 2 ** self.detection_outputs[i]))\n",
    "                cv2.putText(img, '{}'.format(c+1), (x+2, y-5),\n",
    "                            self.font, 2, color, 3)\n",
    "\n",
    "                num_of_grids = (self.grid_per_width * 2 ** self.detection_outputs[i])\n",
    "                grid_x = int(self.grid_cells[i][0] * self.width / num_of_grids)\n",
    "                grid_y = int(self.grid_cells[i][1] * self.height / num_of_grids)\n",
    "                grid_w = int(self.width / (self.grid_per_width * 2 ** self.detection_outputs[i]))\n",
    "                grid_h = int(self.height / (self.grid_per_width * 2 ** self.detection_outputs[i]))\n",
    "                if self.grid_show:\n",
    "                    cv2.rectangle(img, (grid_x, grid_y), (grid_x + grid_w, grid_y + grid_h), color,\n",
    "                                  int(4 / 2 ** self.detection_outputs[i]))\n",
    "                    cv2.circle(img, (self.anchor_centers[i]), 3, color,\n",
    "                               int(4 / 2 ** self.detection_outputs[i]))\n",
    "\n",
    "                ab_center_x = int(self.grid_cells[i][0] * self.width / num_of_grids + grid_w * 0.5)\n",
    "                ab_center_y = int(self.grid_cells[i][1] * self.height / num_of_grids + grid_h * 0.5)\n",
    "                half_box_x = 0.5 * self.anchor_boxes[i][0] * self.width / self.input_square_size\n",
    "                half_box_y = 0.5 * self.anchor_boxes[i][1] * self.height / self.input_square_size\n",
    "                if self.anchor_box_show:\n",
    "                    cv2.rectangle(img, (int(ab_center_x - half_box_x), int(ab_center_y - half_box_y)),\n",
    "                                  (int(ab_center_x + half_box_x), int(ab_center_y + half_box_y)), color,\n",
    "                                  int(4 / 2 ** self.detection_outputs[i]))\n",
    "                    cv2.rectangle(img, (int(ab_center_x - half_box_x), int(ab_center_y - half_box_y)),\n",
    "                                  (int(ab_center_x + half_box_x), int(ab_center_y + half_box_y)), (255,255,255), 1)\n",
    "                    cv2.putText(img, '{}:{} {:.0%} {}({})'.format(c+1, label, confidence, self.anchor_boxes[i], \n",
    "                                    self.detection_outputs[i]), (20, 160 + 30 * c),self.font, 2, color, 3)\n",
    "                else:\n",
    "                    cv2.putText(img, '{}:{} {:.0%}'.format(c+1, label, confidence),\n",
    "                                (20, 160 + 30 * c),self.font, 2, color, 3)\n",
    "        if not self.is_pause:\n",
    "            self.FPS = 1/(time.time() - self.start_time)\n",
    "\n",
    "        cv2.putText(img, 'FPS: {:.2f}'.format(self.FPS), (20, self.height-20),\n",
    "                self.font, 2, (0,255,0), 3)\n",
    "        cv2.imshow('image', img)\n",
    "        \n",
    "def image_resize(image, width = None, height = None, inter = cv2.INTER_AREA):\n",
    "    dim = None\n",
    "    (h, w) = image.shape[:2]\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "    if width is None:\n",
    "        r = height / float(h)\n",
    "        dim = (int(w * r), height)\n",
    "    else:\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h * r))\n",
    "    resized = cv2.resize(image, dim, interpolation = inter)\n",
    "    return resized\n",
    "\n",
    "def keyboard(key, Det):\n",
    "    if key == ord('q'):\n",
    "        return 'quit'\n",
    "    elif key == ord('w'):\n",
    "        Det.IOU_threshold = min(Det.IOU_threshold + 0.01, 0.99)\n",
    "        Det.draw_img()\n",
    "    elif key == ord('s'):\n",
    "        Det.IOU_threshold = max(Det.IOU_threshold - 0.01, 0.01)\n",
    "        Det.draw_img()\n",
    "    elif key == ord('d'):\n",
    "        Det.MIN_confidence = min(Det.MIN_confidence + 0.01, 0.99)\n",
    "        Det.draw_img()\n",
    "    elif key == ord('a'):\n",
    "        Det.MIN_confidence = max(Det.MIN_confidence - 0.01, 0.01)\n",
    "        Det.draw_img()\n",
    "    elif key == ord('W'):\n",
    "        Det.IOU_threshold = min(Det.IOU_threshold + 0.1, 0.99)\n",
    "        Det.draw_img()\n",
    "    elif key == ord('S'):\n",
    "        Det.IOU_threshold = max(Det.IOU_threshold - 0.1, 0.01)\n",
    "        Det.draw_img()\n",
    "    elif key == ord('D'):\n",
    "        Det.MIN_confidence = min(Det.MIN_confidence + 0.1, 0.99)\n",
    "        Det.draw_img()\n",
    "    elif key == ord('A'):\n",
    "        Det.MIN_confidence = max(Det.MIN_confidence - 0.1, 0.01)\n",
    "        Det.draw_img()\n",
    "    elif key == ord('g'):\n",
    "        Det.grid_show = not Det.grid_show\n",
    "        Det.draw_img()\n",
    "    elif key == ord('b'):\n",
    "        Det.anchor_box_show = not Det.anchor_box_show\n",
    "        Det.draw_img()\n",
    "    elif key == 32:\n",
    "        return 'pause-unpause'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "239c0691",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is NOT enabled. OpenCV-4.5.1 will use CPU instead.\n",
      "Detection grid sizes: (13x13), (26x26), (52x52).\n"
     ]
    }
   ],
   "source": [
    "Det = Detection(model_name='yolov4', input_square_size=416, output_height=800)\n",
    "#video = cv2.VideoCapture(r'data\\NY.wmv')\n",
    "video = cv2.VideoCapture(0)\n",
    "\n",
    "run_detection = True\n",
    "while run_detection:\n",
    "    try:\n",
    "        Det.is_pause = False\n",
    "        check, img = video.read()\n",
    "\n",
    "        Det.detect(img)\n",
    "        Det.draw_img()\n",
    "\n",
    "        key = cv2.waitKey(1) \n",
    "        key = keyboard(key, Det)\n",
    "        if key == 'quit':\n",
    "            run_detection = False\n",
    "        elif key == 'pause-unpause':\n",
    "            while True:\n",
    "                Det.is_pause = True\n",
    "                key = cv2.waitKey(0)\n",
    "                key = keyboard(key, Det)\n",
    "                if key == 'quit':\n",
    "                    run_detection = False\n",
    "                    break\n",
    "                elif key == 'pause-unpause':\n",
    "                    break\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "        video.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d997926f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is enabled.\n",
      "Detection grid sizes: (13x13), (26x26), (52x52).\n"
     ]
    }
   ],
   "source": [
    "Det = Detection(model_name='yolov4', input_square_size=416, output_height=800)\n",
    "try:\n",
    "    img = cv2.imread(r'data\\giraffe.jpg')\n",
    "\n",
    "    Det.detect(img)\n",
    "    Det.draw_img()\n",
    "\n",
    "    while True:\n",
    "        Det.is_pause = True\n",
    "        key = cv2.waitKey(0)\n",
    "        key = keyboard(key, Det)\n",
    "        if key == 'quit':\n",
    "            run_detection = False\n",
    "            break\n",
    "except Exception as e: \n",
    "    print(e)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f50494aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is enabled.\n",
      "Detection grid sizes: (13x13), (26x26), (52x52).\n"
     ]
    }
   ],
   "source": [
    "Det = Detection(model_name='yolov4', input_square_size=416, output_height=800)\n",
    "path_to_img = '''\n",
    "https://waukeshadogparks.org/wp-content/uploads/2020/05/12.jpg\n",
    "\n",
    "'''\n",
    "\n",
    "try:\n",
    "    req = urllib.request.urlopen(path_to_img)\n",
    "    arr = np.asarray(bytearray(req.read()), dtype=np.uint8)\n",
    "    img = cv2.imdecode(arr, -1)\n",
    "\n",
    "    Det.detect(img)\n",
    "    Det.draw_img()\n",
    "\n",
    "    while True:\n",
    "        Det.is_pause = True\n",
    "        key = cv2.waitKey(0)\n",
    "        key = keyboard(key, Det)\n",
    "        if key == 'quit':\n",
    "            run_detection = False\n",
    "            break\n",
    "except Exception as e: \n",
    "    print(e)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f05106",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "yolo_tutorial",
   "language": "python",
   "name": "yolo_tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
